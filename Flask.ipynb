{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flask.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-r3WYdSSVa5",
        "outputId": "ae4b0e90-b17d-4738-d6d1-ab1c3e42f890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://w11bw9q2bp-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHPlZdPFSZX3",
        "outputId": "f6d469ba-d17f-4f3e-e4d2-dafdfe650a11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#import random \n",
        "import numpy as np \n",
        "import PIL.Image as Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "# step 1: import Flask \n",
        "from flask import Flask, request\n",
        "\n",
        "# step 2: define Flask app \n",
        "# app = Flask(\"My Flask App\")\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "# step 3: define pages \n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "  return '<h1> Hello from Flask </h1>'\n",
        "\n",
        "@app.route('/help')\n",
        "def help():\n",
        "  return '<h1> Hello from help page </h1>'\n",
        "\n",
        "\n",
        "@app.route('/add')\n",
        "def add():\n",
        "  # to request page \n",
        "  # /add?x=4&y=4\n",
        "  x = int(request.args.get('x'))\n",
        "  y = int(request.args.get('y'))\n",
        "  result = x + y \n",
        "  return '<h1> {}+{}={} </h1>'.format(x, y, result)\n",
        "\n",
        "\n",
        "##################################\n",
        "classifier_model =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\" \n",
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "classifier = tf.keras.Sequential([\n",
        "    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))\n",
        "])\n",
        "\n",
        "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
        "\n",
        "@app.route('/img')\n",
        "def img():\n",
        "  url = request.args.get('url')\n",
        "  # get image and preprocess (open, resize, convert to gray scale)\n",
        "  grace_hopper = tf.keras.utils.get_file('./image.jpg', url)\n",
        "  grace_hopper = Image.open(grace_hopper).resize(IMAGE_SHAPE)\n",
        "  grace_hopper = np.array(grace_hopper)/255.0\n",
        "  # classify \n",
        "  result = classifier.predict(grace_hopper[np.newaxis, ...])\n",
        "  predicted_class = np.argmax(result[0], axis=-1)\n",
        "  predicted_class_name = imagenet_labels[predicted_class]\n",
        "  return '<h1> prediction: {} </h1>'.format(predicted_class_name)\n",
        "\n",
        "\n",
        "\n",
        "# step 4: run app \n",
        "if __name__ == \"__main__\":  \n",
        "  app.run()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\n",
            "16384/10484 [==============================================] - 0s 0us/step\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            "INFO:werkzeug:127.0.0.1 - - [02/Nov/2020 19:29:55] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [02/Nov/2020 19:29:56] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://cdn.shopify.com/s/files/1/0035/2754/0782/articles/International_Flower_Day_1200x1200.jpeg\n",
            "155648/152265 [==============================] - 0s 1us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [02/Nov/2020 19:30:10] \"\u001b[37mGET /img?url=https%3A%2F%2Fcdn.shopify.com%2Fs%2Ffiles%2F1%2F0035%2F2754%2F0782%2Farticles%2FInternational_Flower_Day_1200x1200.jpeg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [02/Nov/2020 19:30:10] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}